from gatox.caching.cache_manager import CacheManager\"nfrom gatox.models.workflow import Workflow\"nfrom gatox.models.repository import Repository\n\nclass DataIngestor:\n\n    @staticmethod\n    def construct_workflow_cache(yml_results):\n        \"\"\"Creates a cache of workflow yml files retrieved from graphQL. Since\n        graphql and REST do not have parity, we still need to use rest for most\n        enumeration calls. This method saves off all yml files, so during org\n        level enumeration if we perform yml enumeration the cached file is used\n        instead of making github REST requests. \n\n        Args:\n            yml_results (list): List of results from individual GraphQL queries\n            (100 nodes at a time).\n        \"\"\"\n\n        cache = CacheManager()\n        for result in yml_results:\n            # If we get any malformed/missing data just skip it and \n            # Gato will fall back to the contents API for these few cases.\n            if not result:\n                continue\n            \n            if 'nameWithOwner' not in result:\n                continue\n\n            owner = result['nameWithOwner']\n            cache.set_empty(owner)\n            # Empty means no yamls, so just skip.\n            if result['object']:\n                for yml_node in result['object']['entries']:\n                    yml_name = yml_node['name']\n                    if yml_name.lower().endswith('yml') or yml_name.lower().endswith('yaml'):\n                        contents = yml_node['object']['text']\n                        wf_wrapper = Workflow(owner, contents, yml_name)\n                        \n                        cache.set_workflow(owner, yml_name, wf_wrapper) \n\n            repo_data = {\n                'full_name': result['nameWithOwner'],\n                'html_url': result['url'],\n                'visibility': 'private' if result['isPrivate'] else 'public',\n                'default_branch': result['defaultBranchRef']['name'] if result['defaultBranchRef'] else 'main',\n                'fork': result['isFork'],\n                'stargazers_count': result['stargazers']['totalCount'],\n                'pushed_at': result['pushedAt'],\n                'permissions': {\n                    'pull': result['viewerPermission'] == 'READ' or \n                      result['viewerPermission'] == 'TRIAGE' or \n                      result['viewerPermission'] == 'WRITE' or \n                      result['viewerPermission'] == 'MAINTAIN' or \n                      result['viewerPermission'] == 'ADMIN' or result['viewerPermission'] == 'forkingAllowed',\n                    'push': result['viewerPermission'] == 'WRITE' or \n                        result['viewerPermission'] == 'MAINTAIN' or \n                        result['viewerPermission'] == 'ADMIN' or result['viewerPermission'] == 'forkingAllowed',\n                    'admin': result['viewerPermission'] == 'ADMIN' or result['viewerPermission'] == 'forkingAllowed'\n                },\n                'archived': result['isArchived'],\n                'isFork': result['isFork'],\n                'environments': []\n            }\n\n            if 'environments' in result and result['environments']:\n                # Capture environments not named github-pages\n                envs = [env['node']['name']  for env in result['environments']['edges'] if env['node']['name'] != 'github-pages']\n                repo_data['environments'] = envs\n            \n            repo_wrapper = Repository(repo_data)\n            cache.set_repository(repo_wrapper)\n